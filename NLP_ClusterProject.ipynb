{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# importing modules\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"porter\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_stopwords(abstract):\n",
    "    stops = set(stopwords.words('english'))\n",
    "    stops.update(['The', 'This','Climate','climate',\n",
    "                  'Adaptation','adaptation','Change','change'])\n",
    "    output= [i for i in abstract if not i in stops] \n",
    "    return output\n",
    "\n",
    "def tokenize(abstract):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(abstract)\n",
    "\n",
    "def lemma(abstract):\n",
    "    lemmatized = []\n",
    "    for w in abstract:\n",
    "        if w.lower() == \"copyright\" or w.lower() == \"c\":\n",
    "            break\n",
    "        lemmatized.append(lemmatizer.lemmatize(w.lower()))\n",
    "    return lemmatized\n",
    "\n",
    "def stemming(abstract):\n",
    "    # Change -> chang\n",
    "    # Climate -> climat\n",
    "    # We use Lemmatization instead\n",
    "    stemmed = []\n",
    "    for w in abstract:\n",
    "        stemmed.append(stemmer.stem(w))\n",
    "    return stemmed\n",
    "\n",
    "def nlp(abstract):\n",
    "    lst_text = lemma(remove_stopwords(tokenize(abstract)))\n",
    "    return ' '.join(lst_text)\n",
    "\n",
    "def clean_master(df):\n",
    "    df = df[df.en != False]\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv('master.csv')\n",
    "    df = clean_master(df)\n",
    "    \n",
    "    df[\"Clean_Abstract\"] = df.apply(\n",
    "        lambda x: nlp(x[\"abstract\"]), axis=1)\n",
    "    \n",
    "    df[\"Abstract_Length\"] = df.apply(\n",
    "        lambda x: len(x[\"Clean_Abstract\"].split(\" \")), axis=1)\n",
    "\n",
    "    df.to_csv(\n",
    "        r'master.csv', index=False)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new = True\n",
    "if create_new:\n",
    "    df = main()\n",
    "else:\n",
    "    print(\"SET create_new = True TO UPDATE master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'climate change adaptation one main strategy address global climate change least developed country small island state lack financial resource adapt climate change vulnerable nation climate change although would economical adapt climate change compared anticipated damage demand capital estimated range hundred billion crucial question manage investment adapt climate change globally study provides overview existing international provision climate finance adaptation it includes provision international financial institution united nation agency bilateral multilateral channel private sector it also explores private sector finance attracted invest climate change adaptation'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_Abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Abstract_Length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Abstract_Length'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\oskar\\Documents\\GitHub\\cluster_project\\NLP_ClusterProject.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     sizes[i] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     a \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39;49m\u001b[39mAbstract_Length\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     sizes[a] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m data \u001b[39m=\u001b[39m sizes\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1012\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m   1011\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1015\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1017\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1120\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Abstract_Length'"
     ]
    }
   ],
   "source": [
    "#Display distribution of abstract length\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(r\"master.csv\")\n",
    "sizes = {}\n",
    "\n",
    "vals = []\n",
    "for i in range(0, 1000):\n",
    "    sizes[i] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    a = row[\"Abstract_Length\"]\n",
    "    sizes[a] += 1\n",
    "\n",
    "\n",
    "data = sizes\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
