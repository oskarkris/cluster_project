{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# importing modules\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"porter\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_stopwords(abstract,stopwords):\n",
    "    output= [i for i in abstract if not i in stopwords] \n",
    "    return output\n",
    "\n",
    "def tokenize(abstract):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(abstract)\n",
    "\n",
    "def lemma(abstract):\n",
    "    lemmatized = []\n",
    "    for w in abstract:\n",
    "        if w.lower() == \"copyright\" or w.lower() == \"c\":\n",
    "            break\n",
    "        lemmatized.append(lemmatizer.lemmatize(w.lower()))\n",
    "    return lemmatized\n",
    "\n",
    "def stemming(abstract):\n",
    "    # Change -> chang\n",
    "    # Climate -> climat\n",
    "    # We use Lemmatization instead\n",
    "    stemmed = []\n",
    "    for w in abstract:\n",
    "        stemmed.append(stemmer.stem(w))\n",
    "    return stemmed\n",
    "\n",
    "def nlp(abstract,stopwords):\n",
    "    lst_text = lemma(remove_stopwords(tokenize(abstract),stopwords))\n",
    "    return ' '.join(lst_text)\n",
    "\n",
    "def clean_master(df):\n",
    "    df = df[df.en != False]\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv('master.csv')\n",
    "    df = clean_master(df)\n",
    "\n",
    "    stops = set(stopwords.words('english'))\n",
    "    print(len(stops))\n",
    "    stops.update(['climate','adaptation'])\n",
    "    print(len(stops))\n",
    "    \n",
    "    df[\"Clean_Abstract\"] = df.apply(\n",
    "        lambda x: nlp(x[\"abstract\"], stops), axis=1)\n",
    "    \n",
    "    df[\"Abstract_Length\"] = df.apply(\n",
    "        lambda x: len(x[\"Clean_Abstract\"].split(\" \")), axis=1)\n",
    "\n",
    "    df.to_csv(\n",
    "        r'master.csv', index=False)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "181\n",
      "climate change one main strategy address global change the least developed country small island state lack financial resource adapt change vulnerable nation change although would economical adapt change compared anticipated damage demand capital estimated range hundred billion the crucial question manage investment adapt change globally this study provides overview existing international provision finance it includes provision international financial institution united nation agency bilateral multilateral channel private sector it also explores private sector finance attracted invest change\n"
     ]
    }
   ],
   "source": [
    "create_new = True\n",
    "if create_new:\n",
    "    df = main()\n",
    "    print(df['Clean_Abstract'][0])\n",
    "else:\n",
    "    print(\"SET create_new = True TO UPDATE master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops2 = set(stopwords.words('english'))\n",
    "stops2.update(['climate','adapt'])\n",
    "test_df[\"Clean_Abstract\"] = df.apply(\n",
    "        lambda x: nlp(x[\"abstract\"],stops2), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change adaptation one main strategy address global change least developed country small island state lack financial resource adapt change vulnerable nation change although would economical adapt change compared anticipated damage demand capital estimated range hundred billion crucial question manage investment adapt change globally study provides overview existing international provision finance adaptation includes provision international financial institution united nation agency bilateral multilateral channel private sector also explores private sector finance attracted invest change adaptation'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Climate change adaptation is one of the main s...\n",
       "1        The absence of clear signals from the Norwegia...\n",
       "2        Building a climate-ready adaptation society is...\n",
       "3        Climate change adaptation frameworks often emp...\n",
       "4        The Intergovernmental Panel on Climate Change ...\n",
       "                               ...                        \n",
       "11721    Cities confronted with unsustainable developme...\n",
       "11722    Rangeland ecosystems worldwide are characteriz...\n",
       "11723    Background: The World Health Organization iden...\n",
       "11724    Traditional flood risk paradigms and associate...\n",
       "11725    Calorimetric methods for the performance asses...\n",
       "Name: abstract, Length: 11726, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Abstract_Length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Abstract_Length'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\oskar\\Documents\\GitHub\\cluster_project\\NLP_ClusterProject.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     sizes[i] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     a \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39;49m\u001b[39mAbstract_Length\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     sizes[a] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oskar/Documents/GitHub/cluster_project/NLP_ClusterProject.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m data \u001b[39m=\u001b[39m sizes\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1012\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m   1011\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1015\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1017\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1120\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Abstract_Length'"
     ]
    }
   ],
   "source": [
    "#Display distribution of abstract length\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(r\"master.csv\")\n",
    "sizes = {}\n",
    "\n",
    "vals = []\n",
    "for i in range(0, 1000):\n",
    "    sizes[i] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    a = row[\"Abstract_Length\"]\n",
    "    sizes[a] += 1\n",
    "\n",
    "\n",
    "data = sizes\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
