{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yellowbrick in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.5)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yellowbrick) (3.7.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yellowbrick) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yellowbrick) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yellowbrick) (1.24.3)\n",
      "Requirement already satisfied: cycler>=0.10.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yellowbrick) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=1.0.0->yellowbrick) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=1.0.0->yellowbrick) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ntn\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "#!pip install seaborn\n",
    "!pip install yellowbrick\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@dennisndungu68/text-classification-using-k-means-33bea24e4a94\n",
    "\n",
    "https://realpython.com/k-means-clustering-python/#how-to-build-a-k-means-clustering-pipeline-in-python\n",
    "\n",
    "https://towardsdatascience.com/kmeans-clustering-for-classification-74b992405d0a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIstedenfor å bruke tfidf-vektorer, bruker vi embeddings lagd av bert\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', min_df=0, stop_words='english')\n",
    "\n",
    "#data = vectorizer.fit_transform(df[\"clean_abstract\"]).toarray()\n",
    "\n",
    "'''\n",
    "Istedenfor å bruke tfidf-vektorer, bruker vi embeddings lagd av bert\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(r\"master.csv\")\n",
    "    embeddings = np.load(r'embeddings_clean_context.npy') # choose correct embeddings\n",
    "    range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "    # cluster_algorithm = input(\"choose algorithm: km, ac, or hc\")\n",
    "    cluster_algorithm = \"km\"\n",
    "\n",
    "    print(df.shape[0])\n",
    "    print(len(embeddings))\n",
    "\n",
    "\n",
    "    df[\"emb\"] = embeddings\n",
    "\n",
    "    df.head(10)\n",
    "    return 0\n",
    "\n",
    "    if cluster_algorithm == \"km\":\n",
    "        kmeans(embeddings, \"emb\", range_n_clusters, 0)\n",
    "\n",
    "    if cluster_algorithm == \"ac\":\n",
    "        return 0\n",
    "    \n",
    "    if cluster_algorithm == \"hc\":\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        print(\"Enter a valid algorithm\")\n",
    "        main()\n",
    "\n",
    "def chooseClusters(labels):\n",
    "    try:\n",
    "        clusters = int(input(\"Choose your preffered amount of clusters\"))\n",
    "        return labels[clusters]\n",
    "    except:\n",
    "        print(\"invalid cluster\")\n",
    "        chooseClusters(labels)\n",
    "\n",
    "def findEmbedding(index, embeddings):\n",
    "    # Takes index of a row in master.csv\n",
    "    # Return its embedding from \"embeddings\"\n",
    "    return \"fix me\"\n",
    "\n",
    "def kmeans(data, column, range, iteration):\n",
    "    fig, ax = plt.subplots(5, 2, figsize=(25,10))\n",
    "    silhouette_avg = []\n",
    "    sse = []\n",
    "    labels = {}\n",
    "    for i in range:\n",
    "        km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "        q, mod = divmod(i, 2)\n",
    "        #silhouette score\n",
    "        ss = silhouette_score(data, km.labels_)\n",
    "        silhouette_avg.append(ss)\n",
    "        # Examine silhuette scores\n",
    "        visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "        visualizer.fit(data)\n",
    "        # use SSE for elbow method\n",
    "        sse.append(km.inertia_)\n",
    "        # Display which iteration we are on\n",
    "        print(i, \" no. of clusters yields an average silhuette score of: \", ss)\n",
    "        # Store labels\n",
    "        labels[i] = km.labels_\n",
    "\n",
    "    print(\"Rember that you should choose cluster size so that the clusters are relatively equal in size\")\n",
    "    plt.plot([0, 0] + silhouette_avg)\n",
    "    plt.plot([0, 0] + sse)\n",
    "    chosen_cluster_amount = chooseClusters(labels)\n",
    "\n",
    "    data_with_clusters = \"fix me\"\n",
    "    '''\n",
    "    save cluster-category to the master.csv in column \"km\"+iteration\n",
    "    data_with_clusters should be the embeddings for the \n",
    "    '''\n",
    "    kmeans(data_with_clusters, range, iteration+1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11727\n",
      "11726\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (11726) does not match length of index (11727)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[21], line 12\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(embeddings))\n\u001b[1;32m---> 12\u001b[0m df[\u001b[39m\"\u001b[39;49m\u001b[39memb\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m embeddings\n\u001b[0;32m     14\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3960\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3958\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3959\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3960\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:4153\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4155\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4156\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4157\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4158\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4159\u001b[0m     ):\n\u001b[0;32m   4160\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4161\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:4880\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4877\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4879\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4880\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4881\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (11726) does not match length of index (11727)"
     ]
    }
   ],
   "source": [
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster']=km.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=100, random_state=42).fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.iat[2489,2] = 2022.0\n",
    "df['year'] = df['year'].astype(str)\n",
    "\n",
    "\n",
    "search = [['Are there social limits to adaptation to climate change?','2009.0'],\n",
    "          ['Limits to adaptation to climate change: a risk approach','2013.0'],\n",
    "          ['Explaining and overcoming barriers to climate change adaptation','2014.0'],\n",
    "          ['Contrasting perspectives on barriers to adaptation in Australian climate change policy','2014.0'],\n",
    "          ['From barriers to limits to climate change adaptation: path dependency and the speed of change','2015.0'],\n",
    "          ['A systematic global stocktake of evidence on human adaptation to climate change','2021.0'],\n",
    "          ['Mapping the evolution and current trends in climate change adaptation science','2021.0'],\n",
    "          ['Climate Change Adaptation on Small Island States: An Assessment of Limits and Constraints','2021.0'],\n",
    "          ['Limits to adaptation: Building an integrated research agenda','2022.0'],\n",
    "          ['A framework to diagnose barriers to climate change adaptation', '2010.0'],\n",
    "          ['Limits to adaptation', '2013.0'],\n",
    "          ['Everyday limits to adaptation', '2022']\n",
    "          ]\n",
    "\n",
    "def find_article(searchinfo):\n",
    "    df_search = pd.DataFrame()\n",
    "    for search in searchinfo:\n",
    "        count = 0\n",
    "        for title,year in zip(df['title'],df['year']):\n",
    "            if search[0] == title and search[1] == year:\n",
    "                df_search = pd.concat([df_search,df[count:count+1]], ignore_index = True)\n",
    "            count = count + 1\n",
    "    return df_search\n",
    "df_search = find_article(search)\n",
    "df_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset into clusters\n",
    "df0 = df[df['cluster'] == 0].reset_index().loc[:,'title':'cluster']\n",
    "df1 = df[df['cluster'] == 1].reset_index().loc[:,'title':'cluster']\n",
    "#df2 = df[df['cluster'] == 2].reset_index().loc[:,'title':'cluster']\n",
    "\n",
    "#df_list = [df0, df1, df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bertopic\n",
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(top_n_words=12,\n",
    "                        #min_topic_size=50,\n",
    "                        nr_topics= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_list:\n",
    "    topic, probs = topic_model.fit_transform(x['clean_abstract'])\n",
    "                                         \n",
    "dftest = pd.DataFrame()\n",
    "dftest['Topic'] = topic_model.get_topic_info()['Topic']\n",
    "dftest['Count'] = topic_model.get_topic_info()['Count']\n",
    "dftest['Name'] = topic_model.get_topic_info()['Name']\n",
    "dftest.to_csv('topics_cluster_'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic, probs = topic_model.fit_transform(df1['clean_abstract'])\n",
    "dftest = pd.DataFrame()\n",
    "dftest['Topic'] = topic_model.get_topic_info()['Topic']\n",
    "dftest['Count'] = topic_model.get_topic_info()['Count']\n",
    "dftest['Name'] = topic_model.get_topic_info()['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
